console.log("ğŸ™ record_voice_unified.js (çµ±åˆæ”¹è‰¯ç‰ˆ) loaded");

const storageRef = firebase.storage();
const isIOS = /iPad|iPhone|iPod/.test(navigator.userAgent);
console.log("ğŸ“± iOS Mode:", isIOS);

// === ãƒ“ãƒ¼ãƒ—éŸ³ï¼ˆé–‹å§‹ãƒ»çµ‚äº†ï¼‰ ===
function playStartBeep() {
  try {
    const ctx = new (window.AudioContext || window.webkitAudioContext)();
    const osc = ctx.createOscillator();
    const gain = ctx.createGain();

    osc.type = "sine";           // ã‚µã‚¤ãƒ³æ³¢
    osc.frequency.value = 880;   // é«˜ã‚ã®ã€Œãƒãƒ³ã€
    gain.gain.setValueAtTime(0.15, ctx.currentTime);
    gain.gain.exponentialRampToValueAtTime(0.001, ctx.currentTime + 0.25);

    osc.connect(gain);
    gain.connect(ctx.destination);
    osc.start();
    osc.stop(ctx.currentTime + 0.25);
  } catch (e) {
    console.warn("ğŸµ é–‹å§‹ãƒ“ãƒ¼ãƒ—å†ç”Ÿå¤±æ•—:", e);
  }
}

function playEndBeep() {
  try {
    const ctx = new (window.AudioContext || window.webkitAudioContext)();
    const osc = ctx.createOscillator();
    const gain = ctx.createGain();

    osc.type = "sine";
    osc.frequency.setValueAtTime(600, ctx.currentTime); // ä½ã‚ã®ã€Œãƒ”ãƒƒã€
    gain.gain.setValueAtTime(0.12, ctx.currentTime);
    gain.gain.exponentialRampToValueAtTime(0.001, ctx.currentTime + 0.15);

    osc.connect(gain);
    gain.connect(ctx.destination);
    osc.start();
    osc.stop(ctx.currentTime + 0.15);
  } catch (e) {
    console.warn("ğŸµ çµ‚äº†ãƒ“ãƒ¼ãƒ—å†ç”Ÿå¤±æ•—:", e);
  }
}


// === Whisperé€ä¿¡ç”¨é–¢æ•°ï¼ˆå…±é€šï¼‰ ===
async function sendToServerForTranscription(audioBlob, meta = {}) {
  try {
    const formData = new FormData();
    formData.append("audio", audioBlob, meta.file_name || `record_${Date.now()}.webm`);
    formData.append("session_id", meta.session_id || window.sessionId || "unknown_session");
    if (meta.storage_path) formData.append("storage_path", meta.storage_path);
    if (meta.record_id) formData.append("record_id", meta.record_id);

    const res = await fetch("/transcribe", { method: "POST", body: formData });
    const data = await res.json();

    if (data.status === "ok") {
      console.log("âœ… WhisperæˆåŠŸ:", data.transcript);
    } else {
      console.warn("âš ï¸ Whisperå¤±æ•—:", data.message || data);
    }
  } catch (err) {
    console.error("âŒ Whisperé€ä¿¡ã‚¨ãƒ©ãƒ¼:", err);
  }
}

// === iOS SafariéŒ²éŸ³ãƒ¢ãƒ¼ãƒ‰ ===
if (isIOS) {
  console.log("ğŸ§ iOS Safari: éŸ³å£°ã‚³ãƒãƒ³ãƒ‰ã§éŒ²éŸ³ã‚’åˆ¶å¾¡");

  async function iosRecordOnce() {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mimeType = MediaRecorder.isTypeSupported("audio/webm")
        ? "audio/webm"
        : "audio/mp4";
      const recorder = new MediaRecorder(stream, { mimeType });
      let chunks = [];

      recorder.ondataavailable = e => chunks.push(e.data);

      recorder.onstop = async () => {
        playEndBeep();
        const blob = new Blob(chunks, { type: mimeType });
        console.log("ğŸ™ iOSéŒ²éŸ³å®Œäº†", blob.size);

        // ç„¡éŸ³ãƒã‚§ãƒƒã‚¯
        if (blob.size < 1000) {
          console.warn("âš ï¸ éŒ²éŸ³ãŒçŸ­ã™ãã‚‹ãŸã‚ä¿å­˜ã‚¹ã‚­ãƒƒãƒ—");
          return;
        }

        const fileName = `ios_${Date.now()}.webm`;
        const path = `audio_records/${fileName}`;
        const storageRef = firebase.storage().ref().child(path);

        // Firebaseã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        await storageRef.put(blob);
        const url = await storageRef.getDownloadURL();

        const sessionId = window.sessionId || "unknown_session";
        const docRef = await db.collection("sessions").doc(sessionId)
          .collection("audio_records").add({
            url: url,
            storage_path: path,
            mime_type: mimeType,
            created_at: firebase.firestore.FieldValue.serverTimestamp(),
          });

        // Whisperã¸è»¢é€
        await sendToServerForTranscription(blob, {
          session_id: sessionId,
          storage_path: path,
          record_id: docRef.id,
          file_name: fileName,
        });
      };

      // âœ… éŒ²éŸ³ã‚¹ã‚¿ãƒ¼ãƒˆï¼ˆ5ç§’ï¼‰
      playStartBeep();
      recorder.start();
      console.log("ğŸ™ éŒ²éŸ³é–‹å§‹");
      setTimeout(() => recorder.stop(), 5000);

    } catch (err) {
      console.error("âŒ iOSéŒ²éŸ³ã‚¨ãƒ©ãƒ¼:", err);
      alert("ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¨±å¯ã—ã¦ãã ã•ã„ã€‚");
    }
  }

  // âœ… éŸ³å£°èªè­˜ã§ã€ŒéŒ²éŸ³ã€ã‚’æ¤œå‡ºã—ãŸã‚‰å‘¼ã³å‡ºã™
  window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
  if (window.SpeechRecognition) {
    const recognition = new SpeechRecognition();
    recognition.lang = "ja-JP";
    recognition.continuous = true;
    recognition.interimResults = false;

    recognition.onresult = (event) => {
      const transcript = event.results[event.results.length - 1][0].transcript.trim();
      console.log("ğŸ¤ éŸ³å£°èªè­˜çµæœ:", transcript);

      if (transcript.includes("éŒ²éŸ³")) {
        console.log("âœ… ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€ŒéŒ²éŸ³ã€ã‚’æ¤œå‡º â†’ éŒ²éŸ³é–‹å§‹");
        iosRecordOnce();
      }
    };

    recognition.onend = () => {
      console.log("ğŸ” éŸ³å£°èªè­˜ãŒçµ‚äº† â†’ è‡ªå‹•å†é–‹");
      recognition.start();
    };

    recognition.onerror = (e) => console.error("éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼:", e);

    recognition.start();
    console.log("ğŸ™ éŸ³å£°èªè­˜ã‚’é–‹å§‹ï¼ˆã€ŒéŒ²éŸ³ã€ã§éŒ²éŸ³é–‹å§‹ï¼‰");
  }
}

// === Android / PC éŸ³å£°èªè­˜ãƒˆãƒªã‚¬ãƒ¼ ===
else if (window.SpeechRecognition || window.webkitSpeechRecognition) {
  const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
  recognition.lang = "ja-JP";
  recognition.continuous = true;
  recognition.interimResults = false;

  recognition.onresult = async (event) => {
    const text = event.results[event.results.length - 1][0].transcript.trim();
    console.log("ğŸ¤ èªè­˜çµæœ:", text);
    if (text.includes("éŒ²éŸ³") || text.includes("ã‚ããŠã‚“")) {
      await startRecordingAndUpload();
    }
  };
  recognition.onend = () => recognition.start();
  recognition.start();
  console.log("âœ… Android éŸ³å£°èªè­˜èµ·å‹•");
}

// === Androidãƒ»PCéŒ²éŸ³é–¢æ•° ===
async function startRecordingAndUpload() {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    const mimeType = MediaRecorder.isTypeSupported("audio/webm")
      ? "audio/webm"
      : "audio/mp4";
    const recorder = new MediaRecorder(stream, { mimeType });
    const chunks = [];

    recorder.ondataavailable = e => chunks.push(e.data);
    recorder.onstop = async () => {
      const audioBlob = new Blob(chunks, { type: mimeType });
      const fileName = `whisper_${Date.now()}.webm`;
      const path = `audio_records/${fileName}`;

      const storage = firebase.storage().ref().child(path);
      await storage.put(audioBlob);
      const downloadURL = await storage.getDownloadURL();

      const sessionId = window.sessionId || "unknown_session";
      const docRef = await db.collection("sessions").doc(sessionId)
        .collection("audio_records").add({
          url: downloadURL,
          storage_path: path,
          mime_type: mimeType,
          created_at: firebase.firestore.FieldValue.serverTimestamp(),
        });

      await sendToServerForTranscription(audioBlob, {
        session_id: sessionId,
        storage_path: path,
        record_id: docRef.id,
        file_name: fileName,
      });
    };

    playStartBeep();
    recorder.start();
    console.log("ğŸ™ éŒ²éŸ³é–‹å§‹");
    setTimeout(() => {
      recorder.stop();
      playEndBeep();   // â† çµ‚äº†éŸ³
    }, 5000);
  } catch (err) {
    console.error("éŒ²éŸ³ã‚¨ãƒ©ãƒ¼:", err);
  }
}
